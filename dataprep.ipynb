{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import dask\n",
    "import asyncio\n",
    "import ray\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = pd.read_csv(\"msd_data/splitting_edited_train_edited.csv\",index_col=None)\n",
    "val_files = pd.read_csv(\"msd_data/splitting_edited_val_edited.csv\",index_col=None)\n",
    "test_files = pd.read_csv(\"msd_data/splitting_edited_test_edited.csv\",index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_files_folders = train_files[\"folders\"]\n",
    "# train_files_number = train_files[\"number\"]\n",
    "\n",
    "# val_files_folders = val_files[\"folders\"]\n",
    "# val_files_folders = val_files[\"number\"]\n",
    "\n",
    "# test_files_folders = test_files[\"folders\"]\n",
    "# test_files_folders = test_files[\"number\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files[\"folders\"] = train_files[\"folders\"].replace(\"^./*\",\"msd_data/\",regex=True)\n",
    "val_files[\"folders\"] = val_files[\"folders\"].replace(\"^./*\",\"msd_data/\",regex=True)\n",
    "test_files[\"folders\"] = test_files[\"folders\"].replace(\"^./*\",\"msd_data/\",regex=True)\n",
    "combined_files = pd.concat([train_files,val_files,test_files])\n",
    "combined_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weights(w1,w2,label):\n",
    "    \"\"\"\n",
    "    W1: Weighting for pixels that are proximal to tissue-transition regions. E.g pixels near the boundary/edges between to different segments\n",
    "        Equates one if gradient between 2 pixels is more than 1 -> If the pixel (x) is besides\n",
    "    W2: Equals one if the class label belongs to an under-represented class\n",
    "    \n",
    "    \"\"\"\n",
    "    # raw_tensor = torch.from_numpy(raw) \n",
    "    label_tensor = torch.from_numpy(label)\n",
    "    \n",
    "    # shape is (H,W)\n",
    "    # print(label_tensor.shape)\n",
    "    # Calculating the weights for W1\n",
    "\n",
    "    # Initialise w1 weight map with all zeroes first\n",
    "    w1_map = torch.zeros(label_tensor.shape)\n",
    "    # print(f\"Initialised w1_map \\n {w1_map.shape}\")\n",
    "    # print(\"Calculating w1 map...\")\n",
    "\n",
    "    num_rows = label_tensor.shape[0]\n",
    "    for row in range(1,num_rows):\n",
    "        # We use row and row-1 so that we won't get an index out of bounds error while\n",
    "        # iterating\n",
    "        first_row = label_tensor[row-1,:]\n",
    "        second_row = label_tensor[row,:]\n",
    "        prev_a = None\n",
    "        prev_b = None\n",
    "\n",
    "        # iterate through each column in each rows\n",
    "        # print(len(first_row))\n",
    "        for col in range(len(first_row)):\n",
    "            a = first_row[col]\n",
    "            b = second_row[col]\n",
    "            if a != b:\n",
    "                # There exists a boundary between a and b, so we should weigh these pixels\n",
    "                w1_map[row-1,col] = 1\n",
    "                w1_map[row,col] = 1\n",
    "            else:\n",
    "                # if we are not at the first(leftmost) col, we check if pixels side by side are the same\n",
    "                # If they are not the same, there exists a boundary between a/b and prev_a/b so we should weigh\n",
    "                # these pixels\n",
    "                if (col != 0) and (prev_a is not None) and (prev_b is not None):\n",
    "                    if a != prev_a:\n",
    "                        w1_map[row-1,col] = 1\n",
    "                        w1_map[row-1,col-1] = 1\n",
    "                    if b != prev_b:\n",
    "                        w1_map[row,col] = 1\n",
    "                        w1_map[row,col-1] = 1\n",
    "                elif (col != 0 ) and (prev_a is None) and (prev_b is None):\n",
    "                    raise Exception(f\"Something went wrong, we were at row {row} col {col} and prev_a or prev_b is NOT none. prev_a:{prev_a}, prev_b:{prev_b}\")\n",
    "                else:\n",
    "                    # We are at the first(leftmost) col, and prev_a and prev_b is None so there is nothing to compare to\n",
    "                    pass\n",
    "            prev_a = a\n",
    "            prev_b = b\n",
    "    # End\n",
    "    # print(f\"Finished calculating W1 map\")\n",
    "    # print(w1_map)\n",
    "    w1_map.float()\n",
    "    # Initialise w2 weight map with all zeroes first\n",
    "    w2_map = torch.zeros(label_tensor.shape)\n",
    "    # class label/idx 2 is the \"dominant\" class so we will weigh the pixels with a class label that is != 2\n",
    "    # w2_map = torch.eq(label_tensor,2).long()\n",
    "    w2_map = torch.eq(label_tensor,2)\n",
    "    # return 1 if value of w2_map = False, else return 0\n",
    "    w2_map = torch.where(w2_map == False,1,0).float()\n",
    "    # weighted_map = 1 + (w1*w1_map) + (w2*w2_map)\n",
    "    # print(f\"W1 : {w1}\")\n",
    "    # print(f\"W1_map is \\n {w1_map}\\n\")\n",
    "    # print(f\"W2 : {w2}\")\n",
    "    # print(f\"W2_map is \\n {w2_map}\\n\")\n",
    "    # print(f\"W1_weighted is : {(w1*w1_map)}\\n\")\n",
    "    # print(f\"W2_weighted is : {(w2*w2_map)}\\n\")\n",
    "    # print(f\"W1_weighted + W2_weighted is {np.add((w1*w1_map),(w2*w2_map))}\")\n",
    "    # print(f\"w1 type is : {w1_map.type()}\")\n",
    "    # print(f\"w2 type is : {w2_map.type()}\")\n",
    "    # print(f\"one_map shape is {one_map.shape}\")\n",
    "    w1_weighted_map = w1 * w1_map\n",
    "    w2_weighted_map = w2 * w2_map\n",
    "    one_map = torch.ones(w1_map.shape)\n",
    "    w1w2_map = torch.add(w1_weighted_map,w2_weighted_map)\n",
    "    weighted_map = torch.add(one_map,w1w2_map)\n",
    "    return weighted_map\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_msd_data(combined_files,dest,w1,w2):\n",
    "    path = os.getcwd()\n",
    "    # make dirs if not exists\n",
    "    if not os.path.exists(dest):\n",
    "        # make dir\n",
    "        data_dest_root = os.path.join(path,dest,\"data\")\n",
    "        display_dest_root = os.path.join(path,dest,\"display\")\n",
    "        seg_dest_root = os.path.join(path,dest,\"segmentations\")\n",
    "        weight_dest_root = os.path.join(path,dest,\"weights\")\n",
    "\n",
    "        data_train_path = os.path.join(data_dest_root,\"train\")\n",
    "        data_val_path = os.path.join(data_dest_root,\"val\")\n",
    "        data_test_path = os.path.join(data_dest_root,\"test\")\n",
    "\n",
    "        display_train_path = os.path.join(display_dest_root,\"train\")\n",
    "        display_val_path = os.path.join(display_dest_root,\"val\")\n",
    "        display_test_path = os.path.join(display_dest_root,\"test\")\n",
    "\n",
    "        seg_train_path = os.path.join(seg_dest_root,\"train\")\n",
    "        seg_val_path = os.path.join(seg_dest_root,\"val\")\n",
    "        seg_test_path = os.path.join(seg_dest_root,\"test\")\n",
    "\n",
    "        weight_train_path = os.path.join(weight_dest_root,\"train\")\n",
    "        weight_val_path = os.path.join(weight_dest_root,\"val\")\n",
    "        weight_test_path = os.path.join(weight_dest_root,\"test\")\n",
    "\n",
    "        pathlib.Path(data_train_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(data_val_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(data_test_path).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "        pathlib.Path(display_train_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(display_val_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(display_test_path).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "        pathlib.Path(seg_train_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(seg_val_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(seg_test_path).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "        pathlib.Path(weight_train_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(weight_val_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(weight_test_path).mkdir(parents=True,exist_ok=True)\n",
    "    else:\n",
    "        print(\"ALRDY EXISTS\")\n",
    "\n",
    "    # iterate through train,val and test\n",
    "    set_files = {}\n",
    "    \n",
    "    for each in combined_files.itertuples():\n",
    "        # Indices are (index,folder,mode,number,partition#)\n",
    "        file_path = each[1]\n",
    "        # file_path = file_path.replace(\"\\\\\",\"/\")\n",
    "        # print(file_path)\n",
    "        file_type = each[2]\n",
    "        file_num = each[3]\n",
    "        file_partition = each[4]\n",
    "        set_files[file_path] = {\"type\":file_type,\"num\":file_num,\"identifier\":file_partition}\n",
    "      \n",
    "        # print(f\"File path is {file_path}, file type is {file_type}, identifier num is {file_identifier}\")\n",
    "    # return set_files\n",
    "    count = 1\n",
    "    path = os.getcwd()\n",
    "    for root,dirs,files in os.walk(\"msd_data/\"):\n",
    "        # if count %100==0:\n",
    "        #     print(count)    \n",
    "        root = root.replace(\"\\\\\",\"/\")\n",
    "        if (root in set_files) and (set_files[root][\"type\"] == \"train\"):\n",
    "            # print(root)\n",
    "            # print(files)\n",
    "            for f in files:\n",
    "                root_split = root.split(\"/\")\n",
    "                prefix = root_split[-1]\n",
    "                display_root = root.replace(\"/Data/\",\"/Display/\")\n",
    "                seg_root = root.replace(\"/Data/\",\"/Segmentations/\")\n",
    "                # no need for weight_root?\n",
    "                weight_root = root.replace(\"/Data/\",\"weights\")\n",
    "\n",
    "                f_new = f.replace(\".tif\",\"_display.png\")\n",
    "                # Removes the _display suffix to bring the filename inline with the ones in the Data folder\n",
    "                f_std = f_new.replace(\"_display.png\",\".png\")\n",
    "                f_seg = f.replace(\".tif\",\".png\")\n",
    "                file_new_name = prefix + f\n",
    "                file_new_name2 = prefix + f_std\n",
    "                file_new_name_seg = prefix + f_seg\n",
    "                weight_file_name = file_new_name_seg.split(\".\")[0]\n",
    "                \n",
    "                # source\n",
    "                source_cur_path = os.path.join(path,root,f)\n",
    "                source_dest_path = os.path.join(data_train_path,file_new_name)\n",
    "                # ground truth segmentation mask\n",
    "                display_cur_path = os.path.join(path,display_root,f_new)\n",
    "                display_dest_path = os.path.join(display_train_path,file_new_name2)\n",
    "                # black background\n",
    "                seg_cur_path = os.path.join(path,seg_root,f_seg)\n",
    "                seg_dest_path = os.path.join(seg_train_path,file_new_name_seg)\n",
    "                # calculate weight of the image\n",
    "                label_img = Image.open(source_cur_path)\n",
    "                label_arr = np.array(label_img)\n",
    "                weight_map = calc_weights(w1,w2,label_arr)\n",
    "                # save weightmap as image\n",
    "                weight_dest_path = os.path.join(weight_train_path,weight_file_name)\n",
    "                weight_map_arr = np.array(weight_map)\n",
    "                \n",
    "\n",
    "                shutil.copy(source_cur_path,source_dest_path)\n",
    "                shutil.copy(display_cur_path,display_dest_path)\n",
    "                shutil.copy(seg_cur_path,seg_dest_path)\n",
    "                np.save(weight_dest_path,weight_map_arr)\n",
    "        elif (root in set_files) and (set_files[root][\"type\"] == \"val\"):\n",
    "        #     print(root)\n",
    "        #     print(files)\n",
    "            for f in files:\n",
    "                root_split = root.split(\"/\")\n",
    "                prefix = root_split[-1]\n",
    "                # print(root)\n",
    "                display_root = root.replace(\"/Data/\",\"/Display/\")\n",
    "                seg_root = root.replace(\"/Data/\",\"/Segmentations/\")\n",
    "\n",
    "                f_new = f.replace(\".tif\",\"_display.png\")\n",
    "                # Removes the _display suffix to bring the filename inline with the ones in the Data folder\n",
    "                f_std = f_new.replace(\"_display.png\",\".png\")\n",
    "                f_seg = f.replace(\".tif\",\".png\")\n",
    "                file_new_name = prefix + f\n",
    "                file_new_name2 = prefix + f_std\n",
    "                file_new_name_seg = prefix + f_seg\n",
    "                weight_file_name = file_new_name_seg.split(\".\")[0]\n",
    "                \n",
    "                # source\n",
    "                source_cur_path = os.path.join(path,root,f)\n",
    "                source_dest_path = os.path.join(data_val_path,file_new_name)\n",
    "                # ground truth segmentation mask\n",
    "                display_cur_path = os.path.join(path,display_root,f_new)\n",
    "                display_dest_path = os.path.join(display_val_path,file_new_name2)\n",
    "                # black background\n",
    "                seg_cur_path = os.path.join(path,seg_root,f_seg)\n",
    "                seg_dest_path = os.path.join(seg_val_path,file_new_name_seg)\n",
    "                # calculate weight of the image\n",
    "                label_img = Image.open(source_cur_path)\n",
    "                label_arr = np.array(label_img)\n",
    "                weight_map = calc_weights(w1,w2,label_arr)\n",
    "                # save weightmap as image\n",
    "                weight_dest_path = os.path.join(weight_val_path,weight_file_name)\n",
    "                weight_map_arr = np.array(weight_map)\n",
    "\n",
    "\n",
    "                shutil.copy(source_cur_path,source_dest_path)\n",
    "                shutil.copy(display_cur_path,display_dest_path)\n",
    "                shutil.copy(seg_cur_path,seg_dest_path)\n",
    "                np.save(weight_dest_path,weight_map_arr)\n",
    "        elif (root in set_files) and (set_files[root][\"type\"] == \"test\"):\n",
    "            for f in files:\n",
    "                root_split = root.split(\"/\")\n",
    "                prefix = root_split[-1]\n",
    "\n",
    "                display_root = root.replace(\"/Data/\",\"/Display/\")\n",
    "\n",
    "                seg_root = root.replace(\"/Data/\",\"/Segmentations/\")\n",
    "\n",
    "                f_new = f.replace(\".tif\",\"_display.png\")\n",
    "                # Removes the _display suffix to bring the filename inline with the ones in the Data folder\n",
    "                f_std = f_new.replace(\"_display.png\",\".png\")\n",
    "                f_seg = f.replace(\".tif\",\".png\")\n",
    "                file_new_name = prefix + f\n",
    "                file_new_name2 = prefix + f_std\n",
    "                file_new_name_seg = prefix + f_seg\n",
    "                weight_file_name = file_new_name_seg.split(\".\")[0]\n",
    "                \n",
    "                # source\n",
    "                source_cur_path = os.path.join(path,root,f)\n",
    "                source_dest_path = os.path.join(data_test_path,file_new_name)\n",
    "                # ground truth segmentation mask\n",
    "                display_cur_path = os.path.join(path,display_root,f_new)\n",
    "                display_dest_path = os.path.join(display_test_path,file_new_name2)\n",
    "                # black background\n",
    "                seg_cur_path = os.path.join(path,seg_root,f_seg)\n",
    "                seg_dest_path = os.path.join(seg_test_path,file_new_name_seg)\n",
    "                # calculate weight of the image\n",
    "                label_img = Image.open(source_cur_path)\n",
    "                label_arr = np.array(label_img)\n",
    "                weight_map = calc_weights(w1,w2,label_arr)\n",
    "                # save weightmap as image\n",
    "                weight_dest_path = os.path.join(weight_test_path,weight_file_name)\n",
    "                weight_map_arr = np.array(weight_map)\n",
    "                \n",
    " \n",
    "                shutil.copy(source_cur_path,source_dest_path)\n",
    "                shutil.copy(display_cur_path,display_dest_path)\n",
    "                shutil.copy(seg_cur_path,seg_dest_path)\n",
    "                np.save(weight_dest_path,weight_map_arr)\n",
    "                \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = \"data_raw_img\"\n",
    "prep_msd_data(combined_files,destination,w1=10,w2=5)\n",
    "\n",
    "# destination = \"data\"\n",
    "# results = prep_msd_data_dask(combined_files,destination,w1=10,w2=5)\n",
    "# results = prep_msd_data_dask(combined_files,destination,w1=10,w2=5)\n",
    "# results = dask.delayed(prep_msd_data_dask)(combined_files,destination,w1=10,w2=5)\n",
    "# final = dask.compute(results)\n",
    "# results.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir(\"data/segmentations/train/\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg = sorted(os.listdir(\"data/segmentations/train\"))\n",
    "# seg_img = Image.open(\"data/segmentations/train/\" + seg[0])\n",
    "# raw = sorted(os.listdir(\"data/data/train\"))\n",
    "# raw_img = Image.open(\"data/data/train/\" + raw[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_array = np.array(raw_img)\n",
    "# seg_array = np.array(seg_img)\n",
    "# np.unique(seg_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_weights(w1,w2,label):\n",
    "#     \"\"\"\n",
    "#     W1: Weighting for pixels that are proximal to tissue-transition regions. E.g pixels near the boundary/edges between to different segments\n",
    "#         Equates one if gradient between 2 pixels is more than 1 -> If the pixel (x) is besides\n",
    "#     W2: Equals one if the class label belongs to an under-represented class\n",
    "    \n",
    "#     \"\"\"\n",
    "#     # raw_tensor = torch.from_numpy(raw) \n",
    "#     label_tensor = torch.from_numpy(label)\n",
    "    \n",
    "#     # shape is (H,W)\n",
    "#     # print(label_tensor.shape)\n",
    "#     # Calculating the weights for W1\n",
    "\n",
    "#     # Initialise w1 weight map with all zeroes first\n",
    "#     w1_map = torch.zeros(label_tensor.shape)\n",
    "#     # print(f\"Initialised w1_map \\n {w1_map.shape}\")\n",
    "#     # print(\"Calculating w1 map...\")\n",
    "\n",
    "#     num_rows = label_tensor.shape[0]\n",
    "#     for row in range(1,num_rows):\n",
    "#         # We use row and row-1 so that we won't get an index out of bounds error while\n",
    "#         # iterating\n",
    "#         first_row = label_tensor[row-1,:]\n",
    "#         second_row = label_tensor[row,:]\n",
    "#         prev_a = None\n",
    "#         prev_b = None\n",
    "\n",
    "#         # iterate through each column in each rows\n",
    "#         # print(len(first_row))\n",
    "#         for col in range(len(first_row)):\n",
    "#             a = first_row[col]\n",
    "#             b = second_row[col]\n",
    "#             if a != b:\n",
    "#                 # There exists a boundary between a and b, so we should weigh these pixels\n",
    "#                 w1_map[row-1,col] = 1\n",
    "#                 w1_map[row,col] = 1\n",
    "#             else:\n",
    "#                 # if we are not at the first(leftmost) col, we check if pixels side by side are the same\n",
    "#                 # If they are not the same, there exists a boundary between a/b and prev_a/b so we should weigh\n",
    "#                 # these pixels\n",
    "#                 if (col != 0) and (prev_a is not None) and (prev_b is not None):\n",
    "#                     if a != prev_a:\n",
    "#                         w1_map[row-1,col] = 1\n",
    "#                         w1_map[row-1,col-1] = 1\n",
    "#                     if b != prev_b:\n",
    "#                         w1_map[row,col] = 1\n",
    "#                         w1_map[row,col-1] = 1\n",
    "#                 elif (col != 0 ) and (prev_a is None) and (prev_b is None):\n",
    "#                     raise Exception(f\"Something went wrong, we were at row {row} col {col} and prev_a or prev_b is NOT none. prev_a:{prev_a}, prev_b:{prev_b}\")\n",
    "#                 else:\n",
    "#                     # We are at the first(leftmost) col, and prev_a and prev_b is None so there is nothing to compare to\n",
    "#                     pass\n",
    "#             prev_a = a\n",
    "#             prev_b = b\n",
    "#     # End\n",
    "#     # print(f\"Finished calculating W1 map\")\n",
    "#     # print(w1_map)\n",
    "#     w1_map.float()\n",
    "#     # Initialise w2 weight map with all zeroes first\n",
    "#     w2_map = torch.zeros(label_tensor.shape)\n",
    "#     # class label/idx 2 is the \"dominant\" class so we will weigh the pixels with a class label that is != 2\n",
    "#     # w2_map = torch.eq(label_tensor,2).long()\n",
    "#     w2_map = torch.eq(label_tensor,2)\n",
    "#     # return 1 if value of w2_map = False, else return 0\n",
    "#     w2_map = torch.where(w2_map == False,1,0).float()\n",
    "#     # weighted_map = 1 + (w1*w1_map) + (w2*w2_map)\n",
    "#     # print(f\"W1 : {w1}\")\n",
    "#     # print(f\"W1_map is \\n {w1_map}\\n\")\n",
    "#     # print(f\"W2 : {w2}\")\n",
    "#     # print(f\"W2_map is \\n {w2_map}\\n\")\n",
    "#     # print(f\"W1_weighted is : {(w1*w1_map)}\\n\")\n",
    "#     # print(f\"W2_weighted is : {(w2*w2_map)}\\n\")\n",
    "#     # print(f\"W1_weighted + W2_weighted is {np.add((w1*w1_map),(w2*w2_map))}\")\n",
    "#     # print(f\"w1 type is : {w1_map.type()}\")\n",
    "#     # print(f\"w2 type is : {w2_map.type()}\")\n",
    "#     # print(f\"one_map shape is {one_map.shape}\")\n",
    "#     w1_weighted_map = w1 * w1_map\n",
    "#     w2_weighted_map = w2 * w2_map\n",
    "#     one_map = torch.ones(w1_map.shape)\n",
    "#     w1w2_map = torch.add(w1_weighted_map,w2_weighted_map)\n",
    "#     weighted_map = torch.add(one_map,w1w2_map)\n",
    "#     return weighted_map\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_weights(10,5,raw_array,seg_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = np.zeros((7,5))\n",
    "# test[2] = [0,0,1,0,0]\n",
    "# test[3] = [1,1,1,1,1]\n",
    "# test[4] = [1,1,1,1,1]\n",
    "# test[5] = [2,2,1,2,2]\n",
    "# test[6] = [2,2,2,2,2]\n",
    "# print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_weights(1,1,raw_array,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dirs(dest:str)->None:\n",
    "    # Checking of dirs should not be async\n",
    "    path = os.getcwd()\n",
    "    if not os.path.exists(dest):\n",
    "        # make dir\n",
    "        data_dest_root = os.path.join(path,dest,\"data\")\n",
    "        display_dest_root = os.path.join(path,dest,\"display\")\n",
    "        seg_dest_root = os.path.join(path,dest,\"segmentations\")\n",
    "        weight_dest_root = os.path.join(path,dest,\"weights\")\n",
    "\n",
    "        data_train_path = os.path.join(data_dest_root,\"train\")\n",
    "        data_val_path = os.path.join(data_dest_root,\"val\")\n",
    "        data_test_path = os.path.join(data_dest_root,\"test\")\n",
    "\n",
    "        display_train_path = os.path.join(display_dest_root,\"train\")\n",
    "        display_val_path = os.path.join(display_dest_root,\"val\")\n",
    "        display_test_path = os.path.join(display_dest_root,\"test\")\n",
    "\n",
    "        seg_train_path = os.path.join(seg_dest_root,\"train\")\n",
    "        seg_val_path = os.path.join(seg_dest_root,\"val\")\n",
    "        seg_test_path = os.path.join(seg_dest_root,\"test\")\n",
    "\n",
    "        weight_train_path = os.path.join(weight_dest_root,\"train\")\n",
    "        weight_val_path = os.path.join(weight_dest_root,\"val\")\n",
    "        weight_test_path = os.path.join(weight_dest_root,\"test\")\n",
    "\n",
    "        pathlib.Path(data_train_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(data_val_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(data_test_path).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "        pathlib.Path(display_train_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(display_val_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(display_test_path).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "        pathlib.Path(seg_train_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(seg_val_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(seg_test_path).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "        pathlib.Path(weight_train_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(weight_val_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(weight_test_path).mkdir(parents=True,exist_ok=True)\n",
    "    else:\n",
    "        print(\"ALRDY EXISTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def calc_weights_async(w1:int,w2:int,queue:asyncio.Queue,output_queue:asyncio.Queue):\n",
    "    \"\"\"\n",
    "    W1: Weighting for pixels that are proximal to tissue-transition regions. E.g pixels near the boundary/edges between to different segments\n",
    "        Equates one if gradient between 2 pixels is more than 1 -> If the pixel (x) is besides\n",
    "    W2: Equals one if the class label belongs to an under-represented class\n",
    "    \n",
    "    \"\"\"\n",
    "    details = queue.get()\n",
    "    label=details[\"source\"]\n",
    "    dest = details[\"dest\"]\n",
    "    label_img = Image.open(label)\n",
    "    label_arr = np.array(label_img)\n",
    "    # raw_tensor = torch.from_numpy(raw) \n",
    "    label_tensor = torch.from_numpy(label_arr)\n",
    "    \n",
    "    # Calculating the weights for W1\n",
    "    # Initialise w1 weight map with all zeroes first\n",
    "    w1_map = torch.zeros(label_tensor.shape)\n",
    "    # print(f\"Initialised w1_map \\n {w1_map.shape}\")\n",
    "    # print(\"Calculating w1 map...\")\n",
    "\n",
    "    num_rows = label_tensor.shape[0]\n",
    "    for row in range(1,num_rows):\n",
    "        # We use row and row-1 so that we won't get an index out of bounds error while\n",
    "        # iterating\n",
    "        first_row = label_tensor[row-1,:]\n",
    "        second_row = label_tensor[row,:]\n",
    "        prev_a = None\n",
    "        prev_b = None\n",
    "\n",
    "        # iterate through each column in each rows\n",
    "        # print(len(first_row))\n",
    "        for col in range(len(first_row)):\n",
    "            a = first_row[col]\n",
    "            b = second_row[col]\n",
    "            if a != b:\n",
    "                # There exists a boundary between a and b, so we should weigh these pixels\n",
    "                w1_map[row-1,col] = 1\n",
    "                w1_map[row,col] = 1\n",
    "            else:\n",
    "                # if we are not at the first(leftmost) col, we check if pixels side by side are the same\n",
    "                # If they are not the same, there exists a boundary between a/b and prev_a/b so we should weigh\n",
    "                # these pixels\n",
    "                if (col != 0) and (prev_a is not None) and (prev_b is not None):\n",
    "                    if a != prev_a:\n",
    "                        w1_map[row-1,col] = 1\n",
    "                        w1_map[row-1,col-1] = 1\n",
    "                    if b != prev_b:\n",
    "                        w1_map[row,col] = 1\n",
    "                        w1_map[row,col-1] = 1\n",
    "                elif (col != 0 ) and (prev_a is None) and (prev_b is None):\n",
    "                    raise Exception(f\"Something went wrong, we were at row {row} col {col} and prev_a or prev_b is NOT none. prev_a:{prev_a}, prev_b:{prev_b}\")\n",
    "                else:\n",
    "                    # We are at the first(leftmost) col, and prev_a and prev_b is None so there is nothing to compare to\n",
    "                    pass\n",
    "            prev_a = a\n",
    "            prev_b = b\n",
    "    # End\n",
    "\n",
    "    # print(f\"Finished calculating W1 map\")\n",
    "    # print(w1_map)\n",
    "    w1_map.float()\n",
    "\n",
    "    # Initialise w2 weight map with all zeroes first\n",
    "    w2_map = torch.zeros(label_tensor.shape)\n",
    "    # class label/idx 2 is the \"dominant\" class so we will weigh the pixels with a class label that is != 2\n",
    "    # w2_map = torch.eq(label_tensor,2).long()\n",
    "    w2_map = torch.eq(label_tensor,2)\n",
    "    # return 1 if value of w2_map = False, else return 0\n",
    "    w2_map = torch.where(w2_map == False,1,0).float()\n",
    "    # weighted_map = 1 + (w1*w1_map) + (w2*w2_map)\n",
    "    # print(f\"W1 : {w1}\")\n",
    "    # print(f\"W1_map is \\n {w1_map}\\n\")\n",
    "    # print(f\"W2 : {w2}\")\n",
    "    # print(f\"W2_map is \\n {w2_map}\\n\")\n",
    "    # print(f\"W1_weighted is : {(w1*w1_map)}\\n\")\n",
    "    # print(f\"W2_weighted is : {(w2*w2_map)}\\n\")\n",
    "    # print(f\"W1_weighted + W2_weighted is {np.add((w1*w1_map),(w2*w2_map))}\")\n",
    "    # print(f\"w1 type is : {w1_map.type()}\")\n",
    "    # print(f\"w2 type is : {w2_map.type()}\")\n",
    "    # print(f\"one_map shape is {one_map.shape}\")\n",
    "    w1_weighted_map = w1 * w1_map\n",
    "    w2_weighted_map = w2 * w2_map\n",
    "    one_map = torch.ones(w1_map.shape)\n",
    "    w1w2_map = torch.add(w1_weighted_map,w2_weighted_map)\n",
    "    weighted_map = torch.add(one_map,w1w2_map)\n",
    "    output_details={\n",
    "        \"dest\":dest,\n",
    "        \"weights\":weighted_map\n",
    "    }\n",
    "    await output_queue.put(output_details)\n",
    "    return weighted_map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_dest_async(train_val_test_paths,path,root,set_files,f,paths_queue,calc_weights_queue):\n",
    "    data_train_path = train_val_test_paths[\"data_train_path\"]\n",
    "    data_val_path = train_val_test_paths[\"data_val_path\"]\n",
    "    data_test_path = train_val_test_paths[\"data_test_path\"]\n",
    "\n",
    "    display_train_path = train_val_test_paths[\"display_train_path\"]\n",
    "    display_val_path = train_val_test_paths[\"display_val_path\"]\n",
    "    display_test_path = train_val_test_paths[\"display_test_path\"]\n",
    "\n",
    "    seg_train_path = train_val_test_paths[\"seg_train_path\"]\n",
    "    seg_val_path = train_val_test_paths[\"seg_val_path\"]\n",
    "    seg_test_path = train_val_test_paths[\"seg_test_path\"]\n",
    "\n",
    "    weight_train_path = train_val_test_paths[\"weight_train_path\"]\n",
    "    weight_val_path = train_val_test_paths[\"weight_val_path\"]\n",
    "    weight_test_path = train_val_test_paths[\"weight_test_path\"]\n",
    "    \n",
    "    root_split = root.split(\"/\")\n",
    "    prefix = root_split[-1]\n",
    "    display_root = root.replace(\"/Data/\",\"/Display/\")\n",
    "    seg_root = root.replace(\"/Data/\",\"/Segmentations/\")\n",
    "    # no need for weight_root?\n",
    "    weight_root = root.replace(\"/Data/\",\"weights\")\n",
    "\n",
    "    f_new = f.replace(\".tif\",\"_display.png\")\n",
    "    # Removes the _display suffix to bring the filename inline with the ones in the Data folder\n",
    "    f_std = f_new.replace(\"_display.png\",\".png\")\n",
    "    f_seg = f.replace(\".tif\",\".png\")\n",
    "    file_new_name = prefix + f\n",
    "    file_new_name2 = prefix + f_std\n",
    "    file_new_name_seg = prefix + f_seg\n",
    "    weight_file_name = file_new_name_seg.split(\".\")[0]\n",
    "\n",
    "    # source\n",
    "    source_cur_path = os.path.join(path,root,f)\n",
    "    # ground truth segmentation mask\n",
    "    display_cur_path = os.path.join(path,display_root,f_new)\n",
    "    # black background\n",
    "    seg_cur_path = os.path.join(path,seg_root,f_seg)\n",
    "    # creation of dest paths are sequential \n",
    "    if (set_files[root][\"type\"] == \"train\"):\n",
    "        source_dest_path = os.path.join(data_train_path,file_new_name)\n",
    "        display_dest_path = os.path.join(display_train_path,file_new_name2)\n",
    "        seg_dest_path = os.path.join(seg_train_path,file_new_name_seg)\n",
    "        weight_dest_path = os.path.join(weight_train_path,weight_file_name)\n",
    "    elif (set_files[root][\"type\"] == \"val\"):\n",
    "        source_dest_path = os.path.join(data_val_path,file_new_name)\n",
    "        display_dest_path = os.path.join(display_val_path,file_new_name2)\n",
    "        seg_dest_path = os.path.join(seg_val_path,file_new_name_seg)\n",
    "        weight_dest_path = os.path.join(weight_val_path,weight_file_name)\n",
    "    elif (set_files[root][\"type\" == \"test\"]):\n",
    "        source_dest_path = os.path.join(data_test_path,file_new_name)\n",
    "        display_dest_path = os.path.join(display_test_path,file_new_name2)\n",
    "        seg_dest_path = os.path.join(seg_test_path,file_new_name_seg)\n",
    "        weight_dest_path = os.path.join(weight_test_path,weight_file_name)\n",
    "    else:\n",
    "        raise Exception(\"Error, unknown type\")\n",
    "    dest_paths = {\n",
    "        \"source_dest_path\":source_dest_path,\n",
    "        \"display_dest_path\":display_dest_path,\n",
    "        \"seg_dest_path\":seg_dest_path,\n",
    "        \"weight_dest_path\":weight_dest_path\n",
    "    }\n",
    "    paths_queue.put(dest_paths)\n",
    "    weights_details={\n",
    "        \"source\":source_cur_path,\n",
    "        \"dest\":weight_dest_path\n",
    "    }\n",
    "    calc_weights_queue.put(weights_details)\n",
    "\n",
    "\n",
    "async def copy_files_async(queue=asyncio.Queue):\n",
    "    paths = queue.get()\n",
    "    shutil.copy(paths[\"source_cur_path\"],paths[\"source_dest_path\"])\n",
    "    shutil.copy(paths[\"display_cur_path\"],paths[\"display_dest_path\"])\n",
    "    shutil.copy(paths[\"seg_cur_path\"],paths[\"seg_dest_path\"])\n",
    "    queue.task_done()\n",
    "\n",
    "\n",
    "async def save_weights_async(queue=asyncio.Queue):\n",
    "    \"\"\"\n",
    "    queue: Contains a dictionary containing the following \n",
    "        dest => Destination file path to save the weights to\n",
    "        weights => The calculated weights    \n",
    "    \"\"\"\n",
    "    details=queue.get()\n",
    "    file_path=details[\"dest\"]\n",
    "    weights=details[\"weights\"]\n",
    "    np.save(file_path,weights)\n",
    "    queue.task_done()\n",
    "\n",
    "async def prep_msd_data_async(combined_files,dest,w1,w2):\n",
    "    \"\"\"\n",
    "    Does the following\n",
    "    1. Check if destination directories exists\n",
    "    1a.Create directories if not exists\n",
    "    2. Get file types(E.g train/test/val),num_files and partitions as an iterable\n",
    "    3. Iterate through the files in the MSD raw dataset and do the following operations:-\n",
    "    3a.Calculate weights asynchronously and add the calculated weights to a queue\n",
    "    3b.Rename the files in the Data,Dispaly,Segmentations folders in the raw data and add the destination filepaths to a queue\n",
    "    4. Async writers/processes will copy/write everything in the queue to their destinations\n",
    "\n",
    "    There are 3 queues:\n",
    "    1. paths_queue -> contains dictionary containing the source and destination paths of MSD images to copy from/to\n",
    "    2. weights_calc_queue -> contains source path of the image that will be used to calculate the weights\n",
    "    3. weights_queue -> contains the \n",
    "    Create_paths creates a dictionary of the paths and adds it to a queue\n",
    "\n",
    "    \"\"\"\n",
    "    check_dirs(dest=dest)\n",
    "    path = os.getcwd()\n",
    "    # make dirs if not exists\n",
    "    if not os.path.exists(dest):\n",
    "        # make dir\n",
    "        data_dest_root = os.path.join(path,dest,\"data\")\n",
    "        display_dest_root = os.path.join(path,dest,\"display\")\n",
    "        seg_dest_root = os.path.join(path,dest,\"segmentations\")\n",
    "        weight_dest_root = os.path.join(path,dest,\"weights\")\n",
    "\n",
    "        data_train_path = os.path.join(data_dest_root,\"train\")\n",
    "        data_val_path = os.path.join(data_dest_root,\"val\")\n",
    "        data_test_path = os.path.join(data_dest_root,\"test\")\n",
    "\n",
    "        display_train_path = os.path.join(display_dest_root,\"train\")\n",
    "        display_val_path = os.path.join(display_dest_root,\"val\")\n",
    "        display_test_path = os.path.join(display_dest_root,\"test\")\n",
    "\n",
    "        seg_train_path = os.path.join(seg_dest_root,\"train\")\n",
    "        seg_val_path = os.path.join(seg_dest_root,\"val\")\n",
    "        seg_test_path = os.path.join(seg_dest_root,\"test\")\n",
    "\n",
    "        weight_train_path = os.path.join(weight_dest_root,\"train\")\n",
    "        weight_val_path = os.path.join(weight_dest_root,\"val\")\n",
    "        weight_test_path = os.path.join(weight_dest_root,\"test\")\n",
    "\n",
    "        pathlib.Path(data_train_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(data_val_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(data_test_path).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "        pathlib.Path(display_train_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(display_val_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(display_test_path).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "        pathlib.Path(seg_train_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(seg_val_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(seg_test_path).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "        pathlib.Path(weight_train_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(weight_val_path).mkdir(parents=True,exist_ok=True)\n",
    "        pathlib.Path(weight_test_path).mkdir(parents=True,exist_ok=True)\n",
    "    else:\n",
    "        print(\"ALRDY EXISTS\")\n",
    "\n",
    "    # iterate through train,val and test\n",
    "    set_files = {}\n",
    "    train_val_test_paths = {\n",
    "        \"data_train_path\" : data_train_path,\n",
    "        \"data_val_path\" : data_val_path,\n",
    "        \"data_test_path\" : data_test_path,\n",
    "        \"display_train_path\" : display_train_path,\n",
    "        \"display_val_path\" : display_val_path,\n",
    "        \"display_test_path\" : display_test_path,\n",
    "        \"seg_train_path\" : seg_train_path,\n",
    "        \"seg_val_path\" : seg_val_path,\n",
    "        \"seg_test_path\" : seg_test_path,\n",
    "        \"weight_train_path\" : weight_train_path,\n",
    "        \"weight_val_path\" : weight_val_path,\n",
    "        \"weight_test_path\" : weight_test_path\n",
    "    }\n",
    "    for each in combined_files.itertuples():\n",
    "        # Indices are (index,folder,mode,number,partition#)\n",
    "        file_path = each[1]\n",
    "        # file_path = file_path.replace(\"\\\\\",\"/\")\n",
    "        # print(file_path)\n",
    "        file_type = each[2]\n",
    "        file_num = each[3]\n",
    "        file_partition = each[4]\n",
    "        set_files[file_path] = {\"type\":file_type,\"num\":file_num,\"identifier\":file_partition}\n",
    "      \n",
    "        # print(f\"File path is {file_path}, file type is {file_type}, identifier num is {file_identifier}\")\n",
    "    # return set_files\n",
    "    count = 1\n",
    "    path = os.getcwd()\n",
    "    paths_queue = asyncio.Queue()\n",
    "    calc_weights_queue = asyncio.Queue()\n",
    "    weights_paths_queue = asyncio.Queue()\n",
    "    for root,dirs,files in os.walk(\"msd_data/\"):\n",
    "        # if count %100==0:\n",
    "        #     print(count)    \n",
    "        root = root.replace(\"\\\\\",\"/\")\n",
    "        if (root in set_files):\n",
    "            for f in files:\n",
    "                # produce and add to the queues\n",
    "                await create_dest_async(train_val_test_paths=train_val_test_paths,path=path,root=root,set_files=set_files,f=f,paths_queue=paths_queue,calc_weights_queue=calc_weights_queue)\n",
    "                await calc_weights_async(w1=w1,w2=w2,queue=calc_weights_queue,output_queue=weights_paths_queue)\n",
    "                # consume the queues\n",
    "                await copy_files_async(queue=paths_queue)\n",
    "                await save_weights_async(queue=weights_paths_queue)\n",
    "\n",
    "                # finish queues\n",
    "                await paths_queue.join()\n",
    "                await calc_weights_queue.join()\n",
    "                await weights_paths_queue.join()\n",
    "\n",
    "asyncio.run(prep_msd_data_async())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def produce(queue:asyncio.Queue):\n",
    "    for i in range(100):\n",
    "        num = np.random.randint(255)\n",
    "        await queue.put(num)\n",
    "        # queue.put(num)\n",
    "\n",
    "async def consume(queue:asyncio.Queue):\n",
    "    while True:\n",
    "        num_to_write = await queue.get()\n",
    "        print(f\"Writing {num_to_write} to disk...\")\n",
    "        print(f\"{num_to_write} written to disk!\")\n",
    "        queue.task_done()\n",
    "\n",
    "async def test_async():\n",
    "    # mkdir\n",
    "    print(f\"making dir....\")\n",
    "    print(f\"Directories created!\")\n",
    "\n",
    "    # create queue\n",
    "    write_queue = asyncio.Queue()\n",
    "    # iterate through dir\n",
    "    await produce()\n",
    "    consumers = [asyncio.create_task(consume(write_queue)) for n in range(3)]\n",
    "    await write_queue.join()\n",
    "    for c in consumers:\n",
    "        c.cancel()\n",
    "\n",
    "\n",
    "asyncio.run(test_async())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import dask\n",
    "import asyncio\n",
    "import ray\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def calc_weights_ray(w1:int,w2:int,queue):\n",
    "    \"\"\"\n",
    "    W1: Weighting for pixels that are proximal to tissue-transition regions. E.g pixels near the boundary/edges between to different segments\n",
    "        Equates one if gradient between 2 pixels is more than 1 -> If the pixel (x) is besides\n",
    "    W2: Equals one if the class label belongs to an under-represented class\n",
    "    \n",
    "    \"\"\"\n",
    "    details = queue\n",
    "    label=details[\"source\"]\n",
    "    dest = details[\"dest\"]\n",
    "    label_img = Image.open(label)\n",
    "    label_arr = np.array(label_img)\n",
    "    # raw_tensor = torch.from_numpy(raw) \n",
    "    label_tensor = torch.from_numpy(label_arr)\n",
    "    \n",
    "    # Calculating the weights for W1\n",
    "    # Initialise w1 weight map with all zeroes first\n",
    "    w1_map = torch.zeros(label_tensor.shape)\n",
    "    # print(f\"Initialised w1_map \\n {w1_map.shape}\")\n",
    "    # print(\"Calculating w1 map...\")\n",
    "\n",
    "    num_rows = label_tensor.shape[0]\n",
    "    for row in range(1,num_rows):\n",
    "        # We use row and row-1 so that we won't get an index out of bounds error while\n",
    "        # iterating\n",
    "        first_row = label_tensor[row-1,:]\n",
    "        second_row = label_tensor[row,:]\n",
    "        prev_a = None\n",
    "        prev_b = None\n",
    "\n",
    "        # iterate through each column in each rows\n",
    "        # print(len(first_row))\n",
    "        for col in range(len(first_row)):\n",
    "            a = first_row[col]\n",
    "            b = second_row[col]\n",
    "            if a != b:\n",
    "                # There exists a boundary between a and b, so we should weigh these pixels\n",
    "                w1_map[row-1,col] = 1\n",
    "                w1_map[row,col] = 1\n",
    "            else:\n",
    "                # if we are not at the first(leftmost) col, we check if pixels side by side are the same\n",
    "                # If they are not the same, there exists a boundary between a/b and prev_a/b so we should weigh\n",
    "                # these pixels\n",
    "                if (col != 0) and (prev_a is not None) and (prev_b is not None):\n",
    "                    if a != prev_a:\n",
    "                        w1_map[row-1,col] = 1\n",
    "                        w1_map[row-1,col-1] = 1\n",
    "                    if b != prev_b:\n",
    "                        w1_map[row,col] = 1\n",
    "                        w1_map[row,col-1] = 1\n",
    "                elif (col != 0 ) and (prev_a is None) and (prev_b is None):\n",
    "                    raise Exception(f\"Something went wrong, we were at row {row} col {col} and prev_a or prev_b is NOT none. prev_a:{prev_a}, prev_b:{prev_b}\")\n",
    "                else:\n",
    "                    # We are at the first(leftmost) col, and prev_a and prev_b is None so there is nothing to compare to\n",
    "                    pass\n",
    "            prev_a = a\n",
    "            prev_b = b\n",
    "    # End\n",
    "\n",
    "    # print(f\"Finished calculating W1 map\")\n",
    "    # print(w1_map)\n",
    "    w1_map.float()\n",
    "\n",
    "    # Initialise w2 weight map with all zeroes first\n",
    "    w2_map = torch.zeros(label_tensor.shape)\n",
    "    # class label/idx 2 is the \"dominant\" class so we will weigh the pixels with a class label that is != 2\n",
    "    # w2_map = torch.eq(label_tensor,2).long()\n",
    "    w2_map = torch.eq(label_tensor,2)\n",
    "    # return 1 if value of w2_map = False, else return 0\n",
    "    w2_map = torch.where(w2_map == False,1,0).float()\n",
    "    # weighted_map = 1 + (w1*w1_map) + (w2*w2_map)\n",
    "    # print(f\"W1 : {w1}\")\n",
    "    # print(f\"W1_map is \\n {w1_map}\\n\")\n",
    "    # print(f\"W2 : {w2}\")\n",
    "    # print(f\"W2_map is \\n {w2_map}\\n\")\n",
    "    # print(f\"W1_weighted is : {(w1*w1_map)}\\n\")\n",
    "    # print(f\"W2_weighted is : {(w2*w2_map)}\\n\")\n",
    "    # print(f\"W1_weighted + W2_weighted is {np.add((w1*w1_map),(w2*w2_map))}\")\n",
    "    # print(f\"w1 type is : {w1_map.type()}\")\n",
    "    # print(f\"w2 type is : {w2_map.type()}\")\n",
    "    # print(f\"one_map shape is {one_map.shape}\")\n",
    "    w1_weighted_map = w1 * w1_map\n",
    "    w2_weighted_map = w2 * w2_map\n",
    "    one_map = torch.ones(w1_map.shape)\n",
    "    w1w2_map = torch.add(w1_weighted_map,w2_weighted_map)\n",
    "    weighted_map = torch.add(one_map,w1w2_map)\n",
    "    output_details={\n",
    "        \"dest\":dest,\n",
    "        \"weights\":weighted_map\n",
    "    }\n",
    "    # output_queue.append(output_details)\n",
    "    return output_details\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 14:13:57,187\tINFO worker.py:1519 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 279\u001b[0m\n\u001b[0;32m    276\u001b[0m test_files[\u001b[39m\"\u001b[39m\u001b[39mfolders\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m test_files[\u001b[39m\"\u001b[39m\u001b[39mfolders\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m^./*\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mmsd_data/\u001b[39m\u001b[39m\"\u001b[39m,regex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    277\u001b[0m combined_files \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([train_files,val_files,test_files])\n\u001b[1;32m--> 279\u001b[0m prep_msd_data_ray(combined_files\u001b[39m=\u001b[39;49mcombined_files,dest\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mray\u001b[39;49m\u001b[39m\"\u001b[39;49m,w1\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,w2\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn [3], line 257\u001b[0m, in \u001b[0;36mprep_msd_data_ray\u001b[1;34m(combined_files, dest, w1, w2)\u001b[0m\n\u001b[0;32m    252\u001b[0m saved_weights_queue\u001b[39m.\u001b[39mappend(saved_weights)\n\u001b[0;32m    256\u001b[0m \u001b[39m# print(f\"Len:{len(copied_files)}\")\u001b[39;00m\n\u001b[1;32m--> 257\u001b[0m copied_files \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39;49mget(files_copied_queue)\n\u001b[0;32m    258\u001b[0m weighted_maps \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39mget(weighted_map_queue)\n\u001b[0;32m    259\u001b[0m saved_weights \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39mget(saved_weights_queue)\n",
      "File \u001b[1;32mc:\\Users\\kenne\\miniconda3\\envs\\msd\\lib\\site-packages\\ray\\_private\\client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m    104\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kenne\\miniconda3\\envs\\msd\\lib\\site-packages\\ray\\_private\\worker.py:2283\u001b[0m, in \u001b[0;36mget\u001b[1;34m(object_refs, timeout)\u001b[0m\n\u001b[0;32m   2278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject_refs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must either be an ObjectRef or a list of ObjectRefs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2280\u001b[0m     )\n\u001b[0;32m   2282\u001b[0m \u001b[39m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[1;32m-> 2283\u001b[0m values, debugger_breakpoint \u001b[39m=\u001b[39m worker\u001b[39m.\u001b[39;49mget_objects(object_refs, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   2284\u001b[0m \u001b[39mfor\u001b[39;00m i, value \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(values):\n\u001b[0;32m   2285\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, RayError):\n",
      "File \u001b[1;32mc:\\Users\\kenne\\miniconda3\\envs\\msd\\lib\\site-packages\\ray\\_private\\worker.py:668\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[1;34m(self, object_refs, timeout)\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    663\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttempting to call `get` on the value \u001b[39m\u001b[39m{\u001b[39;00mobject_ref\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    664\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwhich is not an ray.ObjectRef.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    665\u001b[0m         )\n\u001b[0;32m    667\u001b[0m timeout_ms \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m) \u001b[39mif\u001b[39;00m timeout \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m--> 668\u001b[0m data_metadata_pairs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcore_worker\u001b[39m.\u001b[39;49mget_objects(\n\u001b[0;32m    669\u001b[0m     object_refs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_task_id, timeout_ms\n\u001b[0;32m    670\u001b[0m )\n\u001b[0;32m    671\u001b[0m debugger_breakpoint \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    672\u001b[0m \u001b[39mfor\u001b[39;00m (data, metadata) \u001b[39min\u001b[39;00m data_metadata_pairs:\n",
      "File \u001b[1;32mpython\\ray\\_raylet.pyx:1445\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpython\\ray\\_raylet.pyx:190\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@ray.remote(num_returns=2)\n",
    "def create_dest_ray(train_val_test_paths,path,root,set_files,f,paths_queue,calc_weights_queue):\n",
    "    data_train_path = train_val_test_paths[\"data_train_path\"]\n",
    "    data_val_path = train_val_test_paths[\"data_val_path\"]\n",
    "    data_test_path = train_val_test_paths[\"data_test_path\"]\n",
    "    \n",
    "    display_train_path = train_val_test_paths[\"display_train_path\"]\n",
    "    display_val_path = train_val_test_paths[\"display_val_path\"]\n",
    "    display_test_path = train_val_test_paths[\"display_test_path\"]\n",
    "\n",
    "    seg_train_path = train_val_test_paths[\"seg_train_path\"]\n",
    "    seg_val_path = train_val_test_paths[\"seg_val_path\"]\n",
    "    seg_test_path = train_val_test_paths[\"seg_test_path\"]\n",
    "\n",
    "    weight_train_path = train_val_test_paths[\"weight_train_path\"]\n",
    "    weight_val_path = train_val_test_paths[\"weight_val_path\"]\n",
    "    weight_test_path = train_val_test_paths[\"weight_test_path\"]\n",
    "    \n",
    "    root_split = root.split(\"/\")\n",
    "    prefix = root_split[-1]\n",
    "    display_root = root.replace(\"/Data/\",\"/Display/\")\n",
    "    seg_root = root.replace(\"/Data/\",\"/Segmentations/\")\n",
    "    # no need for weight_root?\n",
    "    weight_root = root.replace(\"/Data/\",\"weights\")\n",
    "\n",
    "    f_new = f.replace(\".tif\",\"_display.png\")\n",
    "    # Removes the _display suffix to bring the filename inline with the ones in the Data folder\n",
    "    f_std = f_new.replace(\"_display.png\",\".png\")\n",
    "    f_seg = f.replace(\".tif\",\".png\")\n",
    "    file_new_name = prefix + f\n",
    "    file_new_name2 = prefix + f_std\n",
    "    file_new_name_seg = prefix + f_seg\n",
    "    weight_file_name = file_new_name_seg.split(\".\")[0]\n",
    "\n",
    "    # source\n",
    "    source_cur_path = os.path.join(path,root,f)\n",
    "    # ground truth segmentation mask\n",
    "    display_cur_path = os.path.join(path,display_root,f_new)\n",
    "    # print(display_cur_path)\n",
    "    # black background\n",
    "    seg_cur_path = os.path.join(path,seg_root,f_seg)\n",
    "    # creation of dest paths are sequential \n",
    "    if (set_files[root][\"type\"] == \"train\"):\n",
    "        source_dest_path = os.path.join(data_train_path,file_new_name)\n",
    "        display_dest_path = os.path.join(display_train_path,file_new_name2)\n",
    "        seg_dest_path = os.path.join(seg_train_path,file_new_name_seg)\n",
    "        weight_dest_path = os.path.join(weight_train_path,weight_file_name)\n",
    "    elif (set_files[root][\"type\"] == \"val\"):\n",
    "        source_dest_path = os.path.join(data_val_path,file_new_name)\n",
    "        display_dest_path = os.path.join(display_val_path,file_new_name2)\n",
    "        seg_dest_path = os.path.join(seg_val_path,file_new_name_seg)\n",
    "        weight_dest_path = os.path.join(weight_val_path,weight_file_name)\n",
    "    elif (set_files[root][\"type\"] == \"test\"):\n",
    "        source_dest_path = os.path.join(data_test_path,file_new_name)\n",
    "        display_dest_path = os.path.join(display_test_path,file_new_name2)\n",
    "        seg_dest_path = os.path.join(seg_test_path,file_new_name_seg)\n",
    "        weight_dest_path = os.path.join(weight_test_path,weight_file_name)\n",
    "    # else:\n",
    "    #     raise Exception(\"Error, unknown type\")\n",
    "    dest_paths = {\n",
    "        \"source_cur_path\":source_cur_path,\n",
    "        \"source_dest_path\":source_dest_path,\n",
    "        \"display_cur_path\":display_cur_path,\n",
    "        \"display_dest_path\":display_dest_path,\n",
    "        \"seg_cur_path\":seg_cur_path,\n",
    "        \"seg_dest_path\":seg_dest_path,\n",
    "        \"weight_dest_path\":weight_dest_path\n",
    "    }\n",
    "    # paths_queue.append(dest_paths)\n",
    "    weights_details={\n",
    "        \"source\":source_cur_path,\n",
    "        \"dest\":weight_dest_path\n",
    "    }\n",
    "    # calc_weights_queue.append(weights_details)\n",
    "    files_copied = copy_files_ray.remote(dest_paths)\n",
    "    # return dest_paths,weights_details\n",
    "    return files_copied,weights_details\n",
    "@ray.remote\n",
    "def copy_files_ray(queue):\n",
    "    paths = queue\n",
    "    if len(paths) > 0:\n",
    "        try:\n",
    "            shutil.copy(paths[\"source_cur_path\"],paths[\"source_dest_path\"])\n",
    "            shutil.copy(paths[\"display_cur_path\"],paths[\"display_dest_path\"])\n",
    "            shutil.copy(paths[\"seg_cur_path\"],paths[\"seg_dest_path\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e} occured while copying files\")\n",
    "    # queue.task_done()\n",
    "\n",
    "@ray.remote\n",
    "def save_weights_ray(queue):\n",
    "    \"\"\"\n",
    "    queue: Contains a dictionary containing the following \n",
    "        dest => Destination file path to save the weights to\n",
    "        weights => The calculated weights    \n",
    "    \"\"\"\n",
    "    details=queue\n",
    "    file_path=details[\"dest\"]\n",
    "    weights=details[\"weights\"]\n",
    "    np.save(file_path,weights)\n",
    "    # queue.task_done()\n",
    "\n",
    "def prep_msd_data_ray(combined_files,dest,w1,w2):\n",
    "    \"\"\"\n",
    "    Does the following\n",
    "    1. Check if destination directories exists\n",
    "    1a.Create directories if not exists\n",
    "    2. Get file types(E.g train/test/val),num_files and partitions as an iterable\n",
    "    3. Iterate through the files in the MSD raw dataset and do the following operations:-\n",
    "    3a.Calculate weights asynchronously and add the calculated weights to a queue\n",
    "    3b.Rename the files in the Data,Dispaly,Segmentations folders in the raw data and add the destination filepaths to a queue\n",
    "    4. Async writers/processes will copy/write everything in the queue to their destinations\n",
    "\n",
    "    There are 3 queues:\n",
    "    1. paths_queue -> contains dictionary containing the source and destination paths of MSD images to copy from/to\n",
    "    2. weights_calc_queue -> contains source path of the image that will be used to calculate the weights\n",
    "    3. weights_queue -> contains the \n",
    "    Create_paths creates a dictionary of the paths and adds it to a queue\n",
    "\n",
    "    \"\"\"\n",
    "    # check_dirs(dest=dest)\n",
    "    path = os.getcwd()\n",
    "    # make dirs if not exists\n",
    "    if os.path.exists(dest):\n",
    "        # make dir\n",
    "        shutil.rmtree(f\"{dest}\")\n",
    "    data_dest_root = os.path.join(path,dest,\"data\")\n",
    "    display_dest_root = os.path.join(path,dest,\"display\")\n",
    "    seg_dest_root = os.path.join(path,dest,\"segmentations\")\n",
    "    weight_dest_root = os.path.join(path,dest,\"weights\")\n",
    "\n",
    "    data_train_path = os.path.join(data_dest_root,\"train\")\n",
    "    data_val_path = os.path.join(data_dest_root,\"val\")\n",
    "    data_test_path = os.path.join(data_dest_root,\"test\")\n",
    "\n",
    "    display_train_path = os.path.join(display_dest_root,\"train\")\n",
    "    display_val_path = os.path.join(display_dest_root,\"val\")\n",
    "    display_test_path = os.path.join(display_dest_root,\"test\")\n",
    "\n",
    "    seg_train_path = os.path.join(seg_dest_root,\"train\")\n",
    "    seg_val_path = os.path.join(seg_dest_root,\"val\")\n",
    "    seg_test_path = os.path.join(seg_dest_root,\"test\")\n",
    "\n",
    "    weight_train_path = os.path.join(weight_dest_root,\"train\")\n",
    "    weight_val_path = os.path.join(weight_dest_root,\"val\")\n",
    "    weight_test_path = os.path.join(weight_dest_root,\"test\")\n",
    "\n",
    "    pathlib.Path(data_train_path).mkdir(parents=True,exist_ok=True)\n",
    "    pathlib.Path(data_val_path).mkdir(parents=True,exist_ok=True)\n",
    "    pathlib.Path(data_test_path).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "    pathlib.Path(display_train_path).mkdir(parents=True,exist_ok=True)\n",
    "    pathlib.Path(display_val_path).mkdir(parents=True,exist_ok=True)\n",
    "    pathlib.Path(display_test_path).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "    pathlib.Path(seg_train_path).mkdir(parents=True,exist_ok=True)\n",
    "    pathlib.Path(seg_val_path).mkdir(parents=True,exist_ok=True)\n",
    "    pathlib.Path(seg_test_path).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "    pathlib.Path(weight_train_path).mkdir(parents=True,exist_ok=True)\n",
    "    pathlib.Path(weight_val_path).mkdir(parents=True,exist_ok=True)\n",
    "    pathlib.Path(weight_test_path).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "    # iterate through train,val and test\n",
    "    set_files = {}\n",
    "    train_val_test_paths = {\n",
    "        \"data_train_path\" : data_train_path,\n",
    "        \"data_val_path\" : data_val_path,\n",
    "        \"data_test_path\" : data_test_path,\n",
    "        \"display_train_path\" : display_train_path,\n",
    "        \"display_val_path\" : display_val_path,\n",
    "        \"display_test_path\" : display_test_path,\n",
    "        \"seg_train_path\" : seg_train_path,\n",
    "        \"seg_val_path\" : seg_val_path,\n",
    "        \"seg_test_path\" : seg_test_path,\n",
    "        \"weight_train_path\" : weight_train_path,\n",
    "        \"weight_val_path\" : weight_val_path,\n",
    "        \"weight_test_path\" : weight_test_path\n",
    "    }\n",
    "    for each in combined_files.itertuples():\n",
    "        # Indices are (index,folder,mode,number,partition#)\n",
    "        file_path = each[1]\n",
    "        # file_path = file_path.replace(\"\\\\\",\"/\")\n",
    "        # print(file_path)\n",
    "        file_type = each[2]\n",
    "        file_num = each[3]\n",
    "        file_partition = each[4]\n",
    "        set_files[file_path] = {\"type\":file_type,\"num\":file_num,\"identifier\":file_partition}\n",
    "      \n",
    "        # print(f\"File path is {file_path}, file type is {file_type}, identifier num is {file_identifier}\")\n",
    "    # return set_files\n",
    "    count = 1\n",
    "    path = os.getcwd()\n",
    "    total_paths_queue = []\n",
    "    paths_queue = []\n",
    "    total_calc_weights_queue = []\n",
    "    calc_weights_queue = []\n",
    "    weights_paths_queue = []\n",
    "    weighted_map_queue = []\n",
    "    saved_weights_queue = []\n",
    "    files_copied_queue = []\n",
    "    MAX_TASKS = 100\n",
    "    count = 0\n",
    "    for root,dirs,files in os.walk(\"msd_data/\"):\n",
    "        # if count %100==0:\n",
    "        #     print(count)    \n",
    "        root = root.replace(\"\\\\\",\"/\")\n",
    "        if (root in set_files):\n",
    "            # print(f\"LENGTH OF FILES: {len(files)}\")\n",
    "            # print(f\"ROOT:{root}\")\n",
    "            # print(f\"DIRS:{dirs}\")\n",
    "            # file_count = 0\n",
    "            for f in files:\n",
    "                # print(count)\n",
    "                # print(f)\n",
    "                if count < MAX_TASKS:\n",
    "                    # print(f\"Creating dest with {f}... \")\n",
    "                    # produce and add to the queues\n",
    "                    # dest_paths,weights_details = create_dest_ray.remote(train_val_test_paths=train_val_test_paths,path=path,root=root,set_files=set_files,f=f,paths_queue=paths_queue,calc_weights_queue=calc_weights_queue)\n",
    "                    files_copied,weights_details = create_dest_ray.remote(train_val_test_paths=train_val_test_paths,path=path,root=root,set_files=set_files,f=f,paths_queue=paths_queue,calc_weights_queue=calc_weights_queue)\n",
    "                    # paths_queue.append(dest_paths)\n",
    "                    files_copied_queue.append(files_copied)\n",
    "                    # calc_weights_queue.append(weights_details)\n",
    "                    # files_copied = copy_files_ray.remote(dest_paths)\n",
    "                    weighted_map = calc_weights_ray.remote(w1=w1,w2=w2,queue=weights_details)\n",
    "                    weighted_map_queue.append(weighted_map)\n",
    "                    saved_weights = save_weights_ray.remote(weighted_map)\n",
    "                    saved_weights_queue.append(saved_weights)\n",
    "                    count += 1\n",
    "                    # file_count+=1\n",
    "                    # weighted_map = calc_weights_ray.remote(w1=w1,w2=w2,queue=calc_weights_queue,output_queue=weights_paths_queue)\n",
    "                    # weights_paths_queue.append(weighted_map)\n",
    "                    # copied_files = copy_files_ray.remote(paths_queue)\n",
    "                    # saved_weights = save_weights_ray.remote(weights_paths_queue)\n",
    "\n",
    "\n",
    "                    # finish queues\n",
    "                    # await paths_queue.join()\n",
    "                    # await calc_weights_queue.join()\n",
    "                    # await weights_paths_queue.join()\n",
    "                else:\n",
    "                    # print(\"ABC\")\n",
    "                    files_copied,weights_details = create_dest_ray.remote(train_val_test_paths=train_val_test_paths,path=path,root=root,set_files=set_files,f=f,paths_queue=paths_queue,calc_weights_queue=calc_weights_queue)\n",
    "                    # paths_queue.append(dest_paths)\n",
    "                    files_copied_queue.append(files_copied)\n",
    "                    # calc_weights_queue.append(weights_details)\n",
    "                    # files_copied = copy_files_ray.remote(dest_paths)\n",
    "                    \n",
    "                    weighted_map = calc_weights_ray.remote(w1=w1,w2=w2,queue=weights_details)\n",
    "                    weighted_map_queue.append(weighted_map)\n",
    "                    saved_weights = save_weights_ray.remote(weighted_map)\n",
    "                    saved_weights_queue.append(saved_weights)\n",
    "\n",
    "\n",
    "                    \n",
    "                    # print(f\"Len:{len(copied_files)}\")\n",
    "                    copied_files = ray.get(files_copied_queue)\n",
    "                    weighted_maps = ray.get(weighted_map_queue)\n",
    "                    saved_weights = ray.get(saved_weights_queue)\n",
    "                    weighted_map_queue = []\n",
    "                    saved_weights_queue = []\n",
    "                    files_copied_queue = []\n",
    "                    count = 0\n",
    "                    # file_count=0\n",
    "    weighted_maps = ray.get(weighted_map_queue)\n",
    "    saved_weights = ray.get(saved_weights_queue)\n",
    "    copied_files = ray.get(files_copied_queue)\n",
    "\n",
    "                \n",
    "ray.init()\n",
    "train_files = pd.read_csv(\"msd_data/splitting_edited_train_edited.csv\",index_col=None)\n",
    "val_files = pd.read_csv(\"msd_data/splitting_edited_val_edited.csv\",index_col=None)\n",
    "test_files = pd.read_csv(\"msd_data/splitting_edited_test_edited.csv\",index_col=None)\n",
    "train_files[\"folders\"] = train_files[\"folders\"].replace(\"^./*\",\"msd_data/\",regex=True)\n",
    "val_files[\"folders\"] = val_files[\"folders\"].replace(\"^./*\",\"msd_data/\",regex=True)\n",
    "test_files[\"folders\"] = test_files[\"folders\"].replace(\"^./*\",\"msd_data/\",regex=True)\n",
    "combined_files = pd.concat([train_files,val_files,test_files])\n",
    "\n",
    "prep_msd_data_ray(combined_files=combined_files,dest=\"ray\",w1=10,w2=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os\n",
    "# import torch\n",
    "\n",
    "# def calc_dice(root_dir):\n",
    "#     \"\"\"\n",
    "    \n",
    "#     \"\"\"\n",
    "#     truth_dir = os.path.join(root_dir,\"truths\")\n",
    "#     pred_dir = os.path.join(root_dir,\"preds\")\n",
    "#     truths = sorted(os.listdir(truth_dir))\n",
    "#     preds = sorted(os.listdir(pred_dir))\n",
    "    \n",
    "#     truth_pred = zip(truths,preds)\n",
    "#     total_dice = []\n",
    "#     for t,p in truth_pred:\n",
    "#         # print(t)\n",
    "#         # print(p)\n",
    "#         # print(\"\\n\")\n",
    "#         t_img = Image.open(f\"{truth_dir}/{t}\")\n",
    "#         p_img = Image.open(f\"{pred_dir}/{p}\")\n",
    "#         print(f\"t_img: {t_img.mode}\")\n",
    "#         print(f\"p_img: {p_img.mode}\")\n",
    "#         t_arr = torch.from_numpy(np.array(t_img))\n",
    "#         p_arr = torch.from_numpy(np.array(p_img))\n",
    "        \n",
    "#         # Transforming both truth n pred into boolean arrays\n",
    "#         t_bool = torch.eq(t_arr,p_arr)\n",
    "#         p_bool = torch.eq(p_arr,p_arr)\n",
    "#         t_b_arr = np.array(t_bool)\n",
    "#         p_b_arr = np.array(p_bool)\n",
    "#         # This gives true positives\n",
    "#         intersection = np.logical_and(t_arr, p_arr) #where A and B are numpy boolean arrays\n",
    "#         # intersection = torch.eq(t_arr, \n",
    "#         # dice = 2 * intersection.sum()/(t_arr.sum() + p_arr.sum())\n",
    "#         # t_b_arr.sum() & p_b_arr.sum() gives us (TP + FP + FN) because True is evaluated as 1 and False is 0\n",
    "#         # Therefore TP=>both true(1), FP(A is 0 if B is 1), FN(Ais 1 when B is 0) and we are essentially just summing up all the 1s.\n",
    "#         dice = 2 * intersection.sum()/(t_b_arr.sum() + p_b_arr.sum())\n",
    "#         total_dice.append(dice)\n",
    "#         # break\n",
    "#     return np.mean(np.array(total_dice))\n",
    "\n",
    "# truth = Image.open(\"results_conv_half_y2_2d_mask_with_loss_label_calc_zerograd_raw/truths/93022_440_622_4383_LNHP_0003.png\")\n",
    "# truth_arr = torch.from_numpy(np.array(truth))\n",
    "# t_unique,t_counts = np.unique(truth_arr,return_counts=True)\n",
    "# # print(truth_arr.shape)\n",
    "# print(t_unique,t_counts)\n",
    "# pred = Image.open(\"results_conv_half_y2_2d_mask_with_loss_label_calc_zerograd_raw/preds/93022_440_622_4383_LNHP_0003.png\")\n",
    "# pred_arr = torch.from_numpy(np.array(pred))\n",
    "# p_unique,p_counts = np.unique(pred_arr,return_counts=True)\n",
    "# plt.imshow(truth_arr)\n",
    "# print(p_unique,p_counts)\n",
    "\n",
    "\n",
    "# # dice = calc_dice(\"results_conv_half_y2_2d_mask_with_loss_label_calc_zerograd\")\n",
    "# # print(dice)\n",
    "\n",
    "# plt.imshow(pred_arr)\n",
    "# print(np.unique(pred_arr))\n",
    "\n",
    "# for root,dirs,files in os.walk(\"results_conv_half_y2_2d_mask_with_loss_label_calc_zerograd/preds/\"):\n",
    "#     for f in files:\n",
    "#         pred = Image.open(os.path.join(root,f))\n",
    "#         pred_arr = np.array(pred)\n",
    "#         print(np.unique(pred_arr))\n",
    "# for root,dirs,files in os.walk(\"results_logits_half_y2_2d_mask_with loss/preds/\"):\n",
    "#     for f in files:\n",
    "#         pred = Image.open(os.path.join(root,f))\n",
    "#         pred_arr = np.array(pred)\n",
    "#         print(np.unique(pred_arr))\n",
    "# # 1161012_1704_2567_15332_RNHP_0000.npy\n",
    "# unknown_weights = np.load(\"test_weights.npy\")\n",
    "# print(unknown_weights[0])\n",
    "# raw_img_weight = np.load(\"data/output//weights/val/1161012_1704_2567_15332_RNHP_0000.npy\")\n",
    "# print(unknown_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2] [ 79103  65083 236742]\n",
      "[0 1 2] [ 79230  56304 245394]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "\n",
    "truth = Image.open(\"results_segweights_final_run_1/truths/93022_440_622_4383_LNHP_0004.png\")\n",
    "truth_arr = torch.from_numpy(np.array(truth))\n",
    "t_unique,t_counts = np.unique(truth_arr,return_counts=True)\n",
    "# print(truth_arr.shape)\n",
    "print(t_unique,t_counts)\n",
    "pred = Image.open(\"results_segweights_final_run_1/preds/93022_440_622_4383_LNHP_0004.png\")\n",
    "pred_arr = torch.from_numpy(np.array(pred))\n",
    "p_unique,p_counts = np.unique(pred_arr,return_counts=True)\n",
    "plt.imshow(truth_arr)\n",
    "print(p_unique,p_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25ab12f3700>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m truth \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(\u001b[39m\"\u001b[39m\u001b[39mresults_segweights_final_run_1/truths/93022_440_622_4383_LNHP_0004.png\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m truth_arr \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39marray(truth))\n\u001b[0;32m      3\u001b[0m t_unique,t_counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(truth_arr,return_counts\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "# truth = Image.open(\"results_segweights_final_run_1/truths/93022_440_622_4383_LNHP_0004.png\")\n",
    "# truth_arr = torch.from_numpy(np.array(truth))\n",
    "# t_unique,t_counts = np.unique(truth_arr,return_counts=True)\n",
    "# # print(truth_arr.shape)\n",
    "# print(t_unique,t_counts)\n",
    "# pred = Image.open(\"results_segweights_final_run_1/preds/93022_440_622_4383_LNHP_0004.png\")\n",
    "# pred_arr = torch.from_numpy(np.array(pred))\n",
    "# p_unique,p_counts = np.unique(pred_arr,return_counts=True)\n",
    "# plt.imshow(truth_arr)\n",
    "# print(p_unique,p_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20c440d2ca0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'results_segweights_run_1_half_y2_conv/display'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m os\u001b[39m.\u001b[39;49mmkdir(\u001b[39m\"\u001b[39;49m\u001b[39mresults_segweights_run_1_half_y2_conv/display\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'results_segweights_run_1_half_y2_conv/display'"
     ]
    }
   ],
   "source": [
    "os.mkdir(\"results_segweights_run_1_half_y2_conv/display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for root,dirs,files in os.walk(\"results_segweights_run_1_half_y2_conv/preds/\"):\n",
    "    for f in files:\n",
    "        pred = Image.open(os.path.join(root,f))\n",
    "        pred_arr = np.array(pred)\n",
    "        pred_save = plt.imsave(\"results_segweights_final_run_3/display/\" + f\"{f}\",pred_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dice testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Dice\n",
    "import torch as th\n",
    "\n",
    "def test_dice(y_true,y_pred):\n",
    "    pred_clone = y_pred.clone()\n",
    "    true_clone = y_true.clone()\n",
    "    \n",
    "    pred_unique = th.unique(y_pred)\n",
    "    true_unique = th.unique(y_true)\n",
    "    print(f\"pred unique: {pred_unique}\")\n",
    "    print(f\"truth unique: {true_unique}\")\n",
    "    for i in range(len(pred_unique)):\n",
    "        print(pred_clone[y_pred==pred_unique[i]])\n",
    "        pred_clone[y_pred==pred_unique[i]] = i\n",
    "        print(pred_clone[y_pred==pred_unique[i]])\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    for i in range(len(true_unique)):\n",
    "        true_clone[y_true==true_unique[i]] = i\n",
    "\n",
    "    multiclass_dice = Dice(num_classes=3,average=\"macro\")\n",
    "    multiclass_dice = multiclass_dice(pred_clone, true_clone)\n",
    "    \n",
    "    return float(multiclass_dice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msd_dice(y_true,y_pred):\n",
    "    pred_clone = y_pred.clone()\n",
    "    true_clone = y_true.clone()\n",
    "    \n",
    "    pred_unique = th.unique(y_pred)\n",
    "    true_unique = th.unique(y_true)\n",
    "    \n",
    "    dices = []\n",
    "    pred_list = []\n",
    "    true_list = []\n",
    "    # compare by each class\n",
    "    for i in range(len(pred_unique)):\n",
    "        # print(cls)\n",
    "        pred_clone[pred_clone==pred_unique[i]] = i\n",
    "    \n",
    "    for i in range(len(true_unique)):\n",
    "        # print(cls)\n",
    "        true_clone[true_clone==true_unique[i]] = i\n",
    "\n",
    "    for i in range(len(pred_unique)):\n",
    "        pred_bool = th.where(pred_clone == i,True,False)\n",
    "        true_bool = th.where(true_clone == i,True,False)\n",
    "        pred_list.append(pred_bool)\n",
    "        true_list.append(true_bool)\n",
    "\n",
    "    for i in range(len(pred_unique)):\n",
    "        intersection = th.logical_and(pred_list[i],true_list[i])\n",
    "        dice = 2 * intersection.sum()/(pred_list[i].sum() + true_list[i].sum())\n",
    "        print(dice)\n",
    "        dices.append(dice)\n",
    "    return np.average(dices)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9986)\n",
      "tensor(0.9354)\n",
      "tensor(0.9840)\n",
      "0.97264916\n"
     ]
    }
   ],
   "source": [
    "cloned = msd_dice(truth_arr,pred_arr)\n",
    "print(cloned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred unique: tensor([0, 1, 2], dtype=torch.uint8)\n",
      "truth unique: tensor([0, 1, 2], dtype=torch.uint8)\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.uint8)\n",
      "\n",
      "\n",
      "tensor([1, 1, 1,  ..., 1, 1, 1], dtype=torch.uint8)\n",
      "tensor([1, 1, 1,  ..., 1, 1, 1], dtype=torch.uint8)\n",
      "\n",
      "\n",
      "tensor([2, 2, 2,  ..., 2, 2, 2], dtype=torch.uint8)\n",
      "tensor([2, 2, 2,  ..., 2, 2, 2], dtype=torch.uint8)\n",
      "\n",
      "\n",
      "0.9726492166519165\n"
     ]
    }
   ],
   "source": [
    "dice = test_dice(truth_arr,pred_arr)\n",
    "print(dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([496, 768])\n",
      "torch.Size([496, 768])\n"
     ]
    }
   ],
   "source": [
    "print(pred_arr.shape)\n",
    "print(truth_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = Image.open(\"final_results/truths/93022_440_622_4383_LNHP_0004.png\")\n",
    "truth_arr = torch.from_numpy(np.array(truth))\n",
    "\n",
    "pred = Image.open(\"final_results/preds/93022_440_622_4383_LNHP_0004.png\")\n",
    "pred_arr = torch.from_numpy(np.array(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred unique: tensor([0, 1, 2], dtype=torch.uint8)\n",
      "truth unique: tensor([0, 1, 2], dtype=torch.uint8)\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.uint8)\n",
      "\n",
      "\n",
      "tensor([1, 1, 1,  ..., 1, 1, 1], dtype=torch.uint8)\n",
      "tensor([1, 1, 1,  ..., 1, 1, 1], dtype=torch.uint8)\n",
      "\n",
      "\n",
      "tensor([2, 2, 2,  ..., 2, 2, 2], dtype=torch.uint8)\n",
      "tensor([2, 2, 2,  ..., 2, 2, 2], dtype=torch.uint8)\n",
      "\n",
      "\n",
      "0.9726492166519165\n"
     ]
    }
   ],
   "source": [
    "# truth = Image.open(\"final_results/truths/93022_440_622_4383_LNHP_0004.png\")\n",
    "# truth_arr = torch.from_numpy(np.array(truth))\n",
    "\n",
    "# pred = Image.open(\"final_results/preds/93022_440_622_4383_LNHP_0004.png\")\n",
    "# pred_arr = torch.from_numpy(np.array(pred))\n",
    "\n",
    "dice = test_dice(truth_arr,pred_arr)\n",
    "print(dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "cur_date = date.today().strftime(\"%d%m%Y\")\n",
    "# print(cur_date)\n",
    "# str_date = str(cur_date).replace(\"-\",\"\")\n",
    "# print(str_date)\n",
    "num_folders = len(next(os.walk(\"data_snakemake/data\"))[1])\n",
    "print(num_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kenne\\fedseg\\data1/synthetic\\25112022\n",
      "1\n",
      "c:\\Users\\kenne\\fedseg\\data1/synthetic\\25112022\\1\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "cur_date = date.today().strftime(\"%d%m%Y\")\n",
    "dest = \"data1/synthetic\"\n",
    "home = os.path.join(path,dest,cur_date)\n",
    "print(home)\n",
    "num_folders = str(len(next(os.walk(home))[1]) + 1)\n",
    "print(num_folders)\n",
    "home = os.path.join(path,dest,cur_date,num_folders)\n",
    "print(home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "roots = []\n",
    "directories = []\n",
    "files  =[]\n",
    "for root,dirs,file in os.walk(\"data_integrated/25112022/run_01/\"):\n",
    "    # directories.append(dirs)\n",
    "    roots.append(root)\n",
    "    directories.append(dirs)\n",
    "    # if len(dirs)>0:\n",
    "    #     directories.append(dirs)\n",
    "    files.append(file)\n",
    "#     print(dirs)\n",
    "#     print(root)\n",
    "#     print(files)\n",
    "    # print(root)\n",
    "# print(roots[5])\n",
    "# print(\"evaluateewqewq\" in roots[5])\n",
    "# print(directories)\n",
    "def create_mappings(base_dir,run_date,run_id):\n",
    "    roots = []\n",
    "    directories = []\n",
    "    files = []\n",
    "    for root,dirs,file in os.walk(f\"{base_dir}/{run_date}/{run_id}\"):\n",
    "        roots.append(root)\n",
    "        if len(dirs) > 0:\n",
    "            directories.append(dirs)\n",
    "        files.append(file)\n",
    "    for folder in directories[0]:\n",
    "        print(folder)\n",
    "        pathlib.Path(f\"{base_dir}/{run_date}/{run_id}/{folder}/mappings.csv\").mkdir(parents=True,exist_ok=True)\n",
    "# create_mappings(\"data_integrated\",\"25112022\",\"run_01\")\n",
    "print(len(roots))\n",
    "# print(roots)\n",
    "# print(len(directories))\n",
    "# print(len(files))\n",
    "# print(roots)\n",
    "# print(directories)\n",
    "# print(files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice(truth:torch.tensor,pred:torch.tensor)->float:\n",
    "    \"\"\"\n",
    "    Calculates binary dice for each class and then returns the average dice across all classes\n",
    "\n",
    "    Args:\n",
    "        truth (torch.tensor): Ground truth\n",
    "        pred (torch.tensor): Predictions from model\n",
    "\n",
    "    Returns:\n",
    "        dices: Dictionary containing the dice score of each class, and the average dice across all classes\n",
    "    \"\"\"\n",
    "    pred_cpu = pred.cpu()\n",
    "    true_cpu = truth.cpu()\n",
    "    \n",
    "    pred_unique = torch.unique(pred_cpu)\n",
    "    true_unique = torch.unique(true_cpu)\n",
    "    \n",
    "    # dices = []\n",
    "    dices = dict()\n",
    "    pred_list = []\n",
    "    true_list = []\n",
    "\n",
    "    # convert the classes into 0,1,2,3,4,.....\n",
    "    # E.g [banana,apple,lemon] -> [0,1,2]\n",
    "    for i in range(len(pred_unique)):\n",
    "        pred_cpu[pred_cpu==pred_unique[i]] = i\n",
    "    \n",
    "    for i in range(len(true_unique)):\n",
    "        # print(cls)\n",
    "        true_cpu[true_cpu==true_unique[i]] = i\n",
    "\n",
    "    # Converts each class(0,1,2,3....) into boolean arrays and append them to a list\n",
    "    # E.g\n",
    "    # [0,0,0]    [1,1,1] [0,0,0] [0,0,0]\n",
    "    # [1,1,1] => [0,0,0],[1,1,1],[0,0,0]\n",
    "    # [2,2,2]    [0,0,0] [0,0,0] [1,1,1]\n",
    "    # The resulting list will contain all the classes, with their index in the list corresponding to their class\n",
    "    # E.g index[0] => class label 0\n",
    "    for i in range(len(pred_unique)):\n",
    "        pred_bool = torch.where(pred_cpu == i,True,False)\n",
    "        true_bool = torch.where(true_cpu == i,True,False)\n",
    "        pred_list.append(pred_bool)\n",
    "        true_list.append(true_bool)\n",
    "\n",
    "    for i in range(len(pred_unique)):\n",
    "        intersection = torch.logical_and(pred_list[i],true_list[i])\n",
    "        dice = 2 * intersection.sum()/(pred_list[i].sum() + true_list[i].sum())\n",
    "        # dices.append(dice)\n",
    "        dices[f\"{i}\"] = dice\n",
    "\n",
    "    dices[\"avg\"] = np.average(list(dices.values()))\n",
    "    # return np.average(dices)\n",
    "    return dices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_individual_dice(root_dir:str):\n",
    "    pred_path = os.path.join(root_dir,\"preds\")\n",
    "    truth_path = os.path.join(root_dir,\"truths\")\n",
    "\n",
    "    preds = sorted(os.listdir(pred_path))\n",
    "    truths = sorted(os.listdir(truth_path))\n",
    "\n",
    "    df = {\n",
    "        \"name\":[],\n",
    "        \"avg\":[],\n",
    "        \"0\":[],\n",
    "        \"1\":[],\n",
    "        \"2\":[]\n",
    "    }\n",
    "    pair = zip(preds,truths)\n",
    "    for p,t in pair:\n",
    "        pred_img_path = os.path.join(pred_path,p)\n",
    "        truth_img_path = os.path.join(truth_path,t)\n",
    "        pred_mask = torch.from_numpy(np.array(Image.open(pred_img_path)))\n",
    "        truth_mask = torch.from_numpy(np.array(Image.open(truth_img_path)))\n",
    "        dice = calc_dice(pred_mask,truth_mask)\n",
    "        # print(dice)\n",
    "        df[\"name\"].append(p)\n",
    "        df[\"avg\"].append(dice[\"avg\"])\n",
    "        df[\"0\"].append(float(dice[\"0\"]))\n",
    "        df[\"1\"].append(float(dice[\"1\"]))\n",
    "        df[\"2\"].append(float(dice[\"2\"]))\n",
    "        # data = pd.DataFrame({\"name\":p,\"avg\":dice[\"avg\"],\"0\":dice[\"0\"],\"1\":dice[\"1\"],\"2\":dice[\"2\"]})\n",
    "        # print(f\"name:{p}, {dice}\")\n",
    "        # pd.concat(data)\n",
    "    return pd.DataFrame(df)\n",
    "\n",
    "\n",
    "# preds = os.listdir(\"results_segweights_run_1_half_y2_conv/preds/\")\n",
    "# print(len(preds))\n",
    "df = calc_individual_dice(root_dir=\"results_segweights_run_1_half_y2_conv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>avg</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1257012_1705_2570_15354_RNHP_0001.png</td>\n",
       "      <td>0.979659</td>\n",
       "      <td>0.971820</td>\n",
       "      <td>0.968539</td>\n",
       "      <td>0.998616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1257012_1705_2570_15354_RNHP_0002.png</td>\n",
       "      <td>0.993585</td>\n",
       "      <td>0.993037</td>\n",
       "      <td>0.988728</td>\n",
       "      <td>0.998990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1257012_1705_2570_15354_RNHP_0003.png</td>\n",
       "      <td>0.993845</td>\n",
       "      <td>0.993826</td>\n",
       "      <td>0.988727</td>\n",
       "      <td>0.998982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1257012_1705_2570_15354_RNHP_0006.png</td>\n",
       "      <td>0.996277</td>\n",
       "      <td>0.997746</td>\n",
       "      <td>0.992438</td>\n",
       "      <td>0.998646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1257012_1705_2570_15354_RNHP_0008.png</td>\n",
       "      <td>0.995656</td>\n",
       "      <td>0.997741</td>\n",
       "      <td>0.991079</td>\n",
       "      <td>0.998148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>93022_440_622_4383_LNHP_0024.png</td>\n",
       "      <td>0.972902</td>\n",
       "      <td>0.997889</td>\n",
       "      <td>0.935098</td>\n",
       "      <td>0.985717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>93022_440_622_4383_LNHP_0025.png</td>\n",
       "      <td>0.971309</td>\n",
       "      <td>0.997961</td>\n",
       "      <td>0.930987</td>\n",
       "      <td>0.984979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>93022_440_622_4383_LNHP_0026.png</td>\n",
       "      <td>0.970121</td>\n",
       "      <td>0.998135</td>\n",
       "      <td>0.928269</td>\n",
       "      <td>0.983960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>93022_440_622_4383_LNHP_0027.png</td>\n",
       "      <td>0.972538</td>\n",
       "      <td>0.998092</td>\n",
       "      <td>0.933490</td>\n",
       "      <td>0.986032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>93022_440_622_4383_LNHP_0028.png</td>\n",
       "      <td>0.972799</td>\n",
       "      <td>0.994470</td>\n",
       "      <td>0.936744</td>\n",
       "      <td>0.987183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name       avg         0         1  \\\n",
       "0     1257012_1705_2570_15354_RNHP_0001.png  0.979659  0.971820  0.968539   \n",
       "1     1257012_1705_2570_15354_RNHP_0002.png  0.993585  0.993037  0.988728   \n",
       "2     1257012_1705_2570_15354_RNHP_0003.png  0.993845  0.993826  0.988727   \n",
       "3     1257012_1705_2570_15354_RNHP_0006.png  0.996277  0.997746  0.992438   \n",
       "4     1257012_1705_2570_15354_RNHP_0008.png  0.995656  0.997741  0.991079   \n",
       "...                                     ...       ...       ...       ...   \n",
       "1195       93022_440_622_4383_LNHP_0024.png  0.972902  0.997889  0.935098   \n",
       "1196       93022_440_622_4383_LNHP_0025.png  0.971309  0.997961  0.930987   \n",
       "1197       93022_440_622_4383_LNHP_0026.png  0.970121  0.998135  0.928269   \n",
       "1198       93022_440_622_4383_LNHP_0027.png  0.972538  0.998092  0.933490   \n",
       "1199       93022_440_622_4383_LNHP_0028.png  0.972799  0.994470  0.936744   \n",
       "\n",
       "             2  \n",
       "0     0.998616  \n",
       "1     0.998990  \n",
       "2     0.998982  \n",
       "3     0.998646  \n",
       "4     0.998148  \n",
       "...        ...  \n",
       "1195  0.985717  \n",
       "1196  0.984979  \n",
       "1197  0.983960  \n",
       "1198  0.986032  \n",
       "1199  0.987183  \n",
       "\n",
       "[1200 rows x 5 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9891269385814667"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"1\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('msd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "612547dc36acad806ee29ca81683fd64a05652320fc9f87285adf577a13144a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
